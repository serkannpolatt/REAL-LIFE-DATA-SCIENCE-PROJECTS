{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f3b776",
   "metadata": {},
   "source": [
    "#### The term hate speech is understood as any type of verbal, written or behavioural communication that attacks or uses derogatory or discriminatory language against a person or group based on what they are, in other words, based on their religion, ethnicity, nationality, race, colour, ancestry, sex or another identity factor. In this article, I will take you through a hate speech detection model with Machine Learning and Python.\n",
    "\n",
    "#### Hate Speech Detection is generally a task of sentiment classification. So for training, a model that can classify hate speech from a certain piece of text can be achieved by training it on a data that is generally used to classify sentiments. So for the task of hate speech detection model, I will use the Twitter data.\n",
    "\n",
    "\n",
    "#### Nefret söylemi terimi, bir kişi veya grubu ne olduğuna, başka bir deyişle dinine, etnik kökenine, dinine, etnik kökenine, karşı saldırıya geçen veya aşağılayıcı veya ayrımcı bir dil kullanan her türlü sözlü, yazılı veya davranışsal iletişim olarak anlaşılmaktadır. milliyet, ırk, renk, soy, cinsiyet veya başka bir kimlik faktörü. Bu yazımda sizlere Machine Learning ve Python ile bir nefret söylemi tespit modelinden bahsedeceğim.\n",
    "\n",
    "#### Nefret Söylemi Tespiti genellikle bir duygu sınıflandırması görevidir. Dolayısıyla, eğitim için, belirli bir metin parçasından nefret söylemini sınıflandırabilen bir model, onu genellikle duyguları sınıflandırmak için kullanılan bir veri üzerinde eğiterek elde edilebilir. Dolayısıyla nefret söylemi tespit modeli görevi için Twitter verilerini kullanacağım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4e296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384890df",
   "metadata": {},
   "source": [
    "# Hate Speech Detection Model\n",
    "#### The data set I will use for the hate speech detection model consists of a test and train set. The training package includes a list of 31,962 tweets, a corresponding ID and a tag 0 or 1 for each tweet. The particular sentiment we need to detect in this dataset is whether or not the tweet is based on hate speech.\n",
    "\n",
    "# Nefret Söylemi Tespit Modeli\n",
    "#### Nefret söylemi tespit modeli için kullanacağım veri seti bir test ve tren setinden oluşuyor. Eğitim paketi, 31.962 tweet'lik bir liste, karşılık gelen bir kimlik ve her tweet için 0 veya 1 etiketi içerir. Bu veri setinde tespit etmemiz gereken özel duygu, tweet'in nefret söylemine dayalı olup olmadığıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0653a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890efd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b9bfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: Index(['id', 'label', 'tweet'], dtype='object') (31962, 3) 31962\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\",train.columns,train.shape,len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12edc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6a6bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: Index(['id', 'tweet'], dtype='object') (17197, 2) 17197\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set:\",test.columns,test.shape,len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd471b",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "#### Data cleaning is the process of preparing incorrectly formated data for analysis by deleting or modifying the incorrectly formatted data which is generally not necessary or useful for data analysis, as it can hinder the process or provide inaccurate results. Now I will perform the process of data cleaning by using the re library in Python:\n",
    "\n",
    "\n",
    "# Veri temizleme\n",
    "#### Veri temizleme, süreci engelleyebileceği veya hatalı sonuçlar verebileceği için genellikle veri analizi için gerekli veya yararlı olmayan yanlış biçimlendirilmiş verileri silerek veya değiştirerek yanlış biçimlendirilmiş verileri analiz için hazırlama işlemidir. Şimdi Python'da re kütüphanesini kullanarak veri temizleme işlemini gerçekleştireceğim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a668230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06da5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df,text_field):\n",
    "    df[text_field] =df[text_field].str.lower()\n",
    "    df[text_field]=df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056ab028",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean=clean_text(test,\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06750e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean=clean_text(train,\"tweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbf9bb",
   "metadata": {},
   "source": [
    "# Handling Imbalanced data for Hate Speech Detection Model\n",
    "#### If you will deeply analyse the task we are working on with context to the data we are using, you will find that the tweets regarding hate speeches are comparatively lesser than others, so this is a situation of an unbalanced data.\n",
    "\n",
    "#### If we will fit this data to train our hate speech detection model, then the model will not generalize any hate speech because the data with context to the hate speech is very less than the positive ones. So in this situation, we need to prepare the data to fit properly in our model.\n",
    "\n",
    "#### There are a number of methods you can use to deal with this. One approach is to use either oversampling or downsampling. In the case of oversampling, we use a function that repeatedly samples, with replacement, from the minority class until the class is the same size as the majority. Let’s see how we can handle this:\n",
    "\n",
    "\n",
    "\n",
    "# Nefret Söylemi Tespit Modeli için Dengesiz Verileri İşleme\n",
    "#### Üzerinde çalıştığımız görevi, kullandığımız veriler bağlamında derinlemesine analiz edecek olursanız, nefret söylemleriyle ilgili tweet'lerin diğerlerine göre nispeten daha az olduğunu göreceksiniz, yani bu dengesiz bir veri durumu.\n",
    "\n",
    "#### Nefret söylemi tespit modelimizi eğitmek için bu verileri sığdırırsak, model herhangi bir nefret söylemini genelleştirmeyecektir çünkü nefret söylemi bağlamına sahip veriler olumlu olanlardan çok daha azdır. Dolayısıyla bu durumda verileri modelimize tam olarak uyacak şekilde hazırlamamız gerekiyor.\n",
    "\n",
    "#### Bununla başa çıkmak için kullanabileceğiniz birkaç yöntem var. Bir yaklaşım, aşırı örnekleme veya alt örnekleme kullanmaktır. Aşırı örnekleme durumunda, sınıf çoğunluk ile aynı boyuta gelene kadar azınlık sınıfından değiştirme ile tekrar tekrar örnekleyen bir işlev kullanırız. Bakalım bununla nasıl başa çıkabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6d01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804aa01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_majority=train_clean[train_clean.label==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61dd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_minority=train_clean[train_clean.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab62b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_minority_upsampled=resample(train_minority,\n",
    "                                 replace=True,\n",
    "                                 n_samples=len(train_majority),\n",
    "                                 random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8be8e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_upsampled=pd.concat([train_minority_upsampled,train_majority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8136a83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29720\n",
       "0    29720\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_upsampled[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086f870",
   "metadata": {},
   "source": [
    "# Creating a Pipeline\n",
    "#### For simplicity and reproducibility of the hate speech detection model, I will use the Scikit-Learn’s pipeline with an SGDClassifier, before training our model:\n",
    "\n",
    "# Boru Hattı Oluşturma\n",
    "#### Nefret söylemi algılama modelinin basitliği ve tekrarlanabilirliği için, modelimizi eğitmeden önce Scikit-Learn'in ardışık düzenini bir SGDClassifier ile kullanacağım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c90b1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a30b560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sgd=Pipeline([\n",
    "    (\"vect\",CountVectorizer()),\n",
    "    (\"tfidf\",TfidfTransformer()),\n",
    "    (\"nb\",SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8dc4b",
   "metadata": {},
   "source": [
    "# Training the Hate Speech Detection Model\n",
    "#### Now, before training the model, let’s split the data into a training set and a test set:\n",
    "\n",
    "# Nefret Söylemi Tespit Modelinin Eğitimi\n",
    "#### Şimdi, modeli eğitmeden önce verileri bir eğitim seti ve bir test seti olarak ayıralım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ed9e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c35d056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_upsampled[\"tweet\"],\n",
    "                                              train_upsampled[\"label\"],random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761f4d3",
   "metadata": {},
   "source": [
    "#### Now let’s train the model and predict the results on the test set using the F1 score method:\n",
    "\n",
    "#### Şimdi modeli eğitelim ve F1 skor yöntemini kullanarak test setindeki sonuçları tahmin edelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26530f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipeline_sgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "385044ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7828761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd858b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693292438991865"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2714a",
   "metadata": {},
   "source": [
    "#### So we got an F1 score of 0.96 per cent which is generally appreciatable. This model can now be deployed and used in production\n",
    "\n",
    "#### Yani yüzde 0.96'lık bir F1 puanı aldık ve bu genellikle takdire şayan. Bu model artık devreye alınabilir ve üretimde kullanılabilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c85720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
